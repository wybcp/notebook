# 数据结构

数据结构具体指同一类数据元素中，各元素之间的相互关系，包括三个组成成分，**数据的逻辑结构**，**数据的存储结构**和**数据运算结构**。

数据结构就是指一组数据的存储结构。

## 常用结构

### 数组

数组（Array）是一种线性表数据结构。它用一组**连续的内存空间**，来存储一组具有相同类型的数据。

- 优点：随机访问，根据下标随机访问的时间复杂度为 O(1)。
- 缺点：数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，就需要做大量的数据搬移工作，时间复杂度是 O(n)。

### [链表](https://time.geekbang.org/column/article/41013)

链表不需要一块连续的内存空间，通过“指针”将一组零散的内存块串联起来使用。

内存块称为链表的“结点”。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址，叫作后继指针 next。

链表本身没有大小的限制，天然地支持动态扩容。

检查链表代码是否正确的边界条件：

- 如果链表为空时，代码是否能正常工作？
- 如果链表只包含一个结点时，代码是否能正常工作？
- 如果链表只包含两个结点时，代码是否能正常工作？
- 代码逻辑在处理头结点和尾结点的时候，是否能正常工作？

常见的链表操作：

- 单链表反转
- 链表中环的检测
- 两个有序的链表合并
- 删除链表倒数第 n 个结点
- 求链表的中间结点

#### 单链表

两个结点是比较特殊的：

- 第一个结点叫作头结点，用来记录链表的基地址，可以遍历得到整条链表。
- 最后一个结点叫作尾结点，指针不是指向下一个结点，而是指向一个空地址 NULL，表示这是链表上最后一个结点。

链表支持数据的查找、插入和删除操作。

- 查找：
  因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点，O(n) 的时间复杂度。
- 插入和删除：
  只需要考虑相邻结点的指针改变

#### 循环链表

循环链表是一种特殊的单链表，跟单链表唯一的区别就在尾结点，尾结点指针是指向链表的头结点。

当要处理的数据具有环型结构特点时，就特别适合采用循环链表。比如著名的[约瑟夫问题](https://zh.wikipedia.org/wiki/%E7%BA%A6%E7%91%9F%E5%A4%AB%E6%96%AF%E9%97%AE%E9%A2%98)。

#### 双向链表

双向链表，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。

如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。

插入、删除操作有优势，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。

用空间换时间的设计思想。

### [跳表（Skip list）](https://time.geekbang.org/column/article/42896)

链表加多级索引的结构，就是跳表。

可以支持快速的插入、删除、查找操作，写起来也不复杂,时间复杂度也是 O(logn)。

Redis 中的有序集合（Sorted Set）就是用跳表来实现的。

空间复杂度是 O(n)。不过，跳表的实现非常灵活，可以通过改变索引构建策略，有效平衡执行效率和内存消耗。

跳表操作的注意事项：

    作为一种动态数据结构，需要某种手段来维护索引与原始链表大小之间的平衡，也就是说，如果链表中结点多了，索引结点就相应地增加一些，避免复杂度退化，以及查找、插入、删除操作性能下降。

    跳表是通过随机函数来维护前面提到的“平衡性”。

    当往跳表中插入数据的时候，可以选择同时将这个数据插入到部分索引层中。如何选择加入哪些索引层呢？

    通过一个随机函数，来决定将这个结点插入到哪几级索引中，比如随机函数生成了值 K，那我们就将这个结点添加到第一级到第 K 级这 K 级索引中。

### 栈

后进先出，先进后出

从栈的操作特性上来看，栈是一种“操作受限”的线性表，只允许在一端插入和删除数据。

当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，应该首选“栈”这种数据结构。

用数组实现的栈，叫作顺序栈，用链表实现的栈，叫作链式栈。

经典的应用场景

- 函数调用栈
- 编译器如何利用栈来实现表达式求值。

### 队列

先进先出

队列跟栈一样，也是一种操作受限的线性表数据结构。最基本的操作：入队 enqueue()，放一个数据到队列尾部；出队 dequeue()，从队列头部取一个元素。

用数组实现的队列叫作顺序队列，用链表实现的队列叫作链式队列。

队列需要两个指针：一个是 head 指针，指向队头；一个是 tail 指针，指向队尾。

边界条件：队空和队满

#### 阻塞队列

在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。

以使用阻塞队列，轻松实现一个“生产者 - 消费者模型”！

#### 并发队列

线程安全的队列。最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。

### 递归（Recursion）

写出递推公式，找到终止条件

#### 递归例子

假如这里有 n 个台阶，每次你可以跨 1 个台阶或者 2 个台阶，请问走这 n 个台阶有多少种走法？

可以根据第一步的走法把所有走法分为两类，第一类是第一步走了 1 个台阶，另一类是第一步走了 2 个台阶。所以 n 个台阶的走法就等于先走 1 阶后，n-1 个台阶的走法加上先走 2 阶后，n-2 个台阶的走法。用公式表示就是：`f(n) = f(n-1)+f(n-2)`

终止条件。当有一个台阶时，我们不需要再继续递归，就只有一种走法。所以 f(1)=1。这个递归终止条件足够吗？我们可以用 n=2，n=3 这样比较小的数试验一下。

n=2 时，f(2)=f(1)+f(0)。如果递归终止条件只有一个 f(1)=1，那 f(2) 就无法求解了。所以除了 f(1)=1 这一个递归终止条件外，还要有 f(0)=1，表示走 0 个台阶有一种走法，不过这样子看起来就不符合正常的逻辑思维了。所以，我们可以把 f(2)=2 作为一种终止条件，表示走 2 个台阶，有两种走法，一步走完或者分两步来走。

所以，递归终止条件就是 f(1)=1，f(2)=2。这个时候，你可以再拿 n=3，n=4 来验证一下，这个终止条件是否足够并且正确。

我们把递归终止条件和刚刚得到的递推公式放到一起就是这样的：

```
f(1) = 1;
f(2) = 2;
f(n) = f(n-1)+f(n-2)
```

最终的递归代码是这样的：

```c
int f(int n) {
    if (n == 1) return 1;
    if (n == 2) return 2;
    return f(n-1) + f(n-2);
}
```

编写递归代码的关键是，只要遇到递归，把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。

递归代码要警惕重复计算，可以将计算过的值保存（键值对）

调试递归:

1. 打印日志发现，递归值。
2. 结合条件断点进行调试。

### [散列表（Hash Table）](https://time.geekbang.org/column/article/64233)

散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。

通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当按照键值查询元素时，用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。

散列函数，定义成 hash(key)，其中 key 表示元素的键值，hash(key) 的值表示经过散列函数计算得到的散列值。

散列函数设计的基本要求：

- 散列函数计算得到的散列值是一个非负整数（因为数组下标是从 0 开始的）；
- 如果 key1 = key2，那 hash(key1) == hash(key2)；
- 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。

#### 散列冲突

再好的散列函数也无法避免散列冲突。

1. 开放寻址法（open addressing）

   如果出现了散列冲突，重新探测一个空闲位置，将其插入。那如何重新探测新的位置呢？一个比较简单的探测方法，线性探测（Linear Probing）。

   当往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。

   二次探测（Quadratic probing）和双重散列（Double hashing）。

2. 链表法

   链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多。

### [二叉树](https://time.geekbang.org/column/article/67856)

二叉树，每个节点最多有两个“叉”，也就是两个子节点，分别是左子节点和右子节点。不过，二叉树并不要求每个节点都有两个子节点，有的节点只有左子节点，有的节点只有右子节点。

- 满二叉树：叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点。
- 完全二叉树：叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大

存储一棵二叉树

- 基于指针或者引用的二叉链式存储法，每个节点有三个字段，其中一个存储数据，另外两个是指向左右子节点的指针。
- 基于数组的顺序存储法。根节点存储在下标 `i = 1` 的位置，那左子节点存储在下标 `2 * i = 2` 的位置，右子节点存储在 `2 * i + 1 = 3` 的位置。以此类推

#### 二叉树的遍历

时间复杂度是 O(n)

经典的方法有三种，前序遍历、中序遍历和后序遍历。其中，前、中、后序，表示的是节点与它的左右子树节点遍历打印的先后顺序。

- 前序遍历，对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。
- 中序遍历，对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树。
- 后序遍历，对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身。

#### [二叉查找树（Binary Search Tree）](https://time.geekbang.org/column/article/68334)

二叉查找树要求，在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值。

中序遍历二叉查找树，可以输出有序的数据序列，时间复杂度是 O(n)，非常高效。因此，二叉查找树也叫作二叉排序树。

二叉查找树在频繁的动态更新过程中，可能会出现树的高度远大于 log<sub>2</sub>n 的情况，从而导致各个操作的效率下降。极端情况下，二叉树会退化为链表，时间复杂度会退化到 O(n)。

##### 支持重复数据的二叉查找树

- 二叉查找树中每一个节点不仅会存储一个数据，因此我们通过链表和支持动态扩容的数组等数据结构，把值相同的数据都存储在同一个节点上。
- 每个节点仍然只存储一个数据。在查找插入位置的过程中，如果碰到一个节点的值，与要插入数据的值相同，将这个要插入的数据放到这个节点的右子树，也就是说，把这个新插入的数据当作大于这个节点的值来处理。

#### [红黑树](https://time.geekbang.org/column/article/68638)

平衡二叉树的严格定义是这样的：二叉树中任意一个节点的左右子树的高度相差不能大于 1。

平衡二叉查找树不仅满足上面平衡二叉树的定义，还满足二叉查找树的特点。

红黑树的英文是“Red-Black Tree”，简称 R-B Tree。它是一种不严格的平衡二叉查找树。

红黑树中的节点，一类被标记为黑色，一类被标记为红色。除此之外，一棵红黑树还需要满足这样几个要求：

- 根节点是黑色的；
- 每个叶子节点都是黑色的空节点（NIL），即叶子节点不存储数据，主要是为了简化红黑树的代码实现而设置的；
- 任何相邻的节点都不能同时为红色，即红色节点是被黑色节点隔开的；
- 每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；

红黑树中包含最多黑色节点的路径不会超过 log<sub>2</sub>n，所以加入红色节点之后，最长路径不会超过 2log<sub>2</sub>n，也就是说，红黑树的高度近似 2log<sub>2</sub>n。

红黑树的插入、删除、查找各种操作性能都比较稳定。

### [堆](https://time.geekbang.org/column/article/69913#previewimg)

堆是一种特殊的树。

- 堆是一个完全二叉树；
- 堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值。

堆排序是一种原地的、时间复杂度为 O(nlogn) 的排序算法。

对于每个节点的值都大于等于子树中每个节点值的堆，叫作“大顶堆”。

对于每个节点的值都小于等于子树中每个节点值的堆，叫作“小顶堆”。

堆中插入一个元素和删除堆顶元素的时间复杂度都是 O(logn)。

#### 堆的应用：优先级队列

优先级队列，按照优先级来出队，优先级最高的，最先出队。

如何实现一个优先级队列呢？方法有很多，但是用堆来实现是最直接、最高效的。这是因为，堆和优先级队列非常相似。一个堆就可以看作一个优先级队列。很多时候，它们只是概念上的区分而已。往优先级队列中插入一个元素，就相当于往堆中插入一个元素；从优先级队列中取出优先级最高的元素，就相当于取出堆顶元素。

很多数据结构和算法都要依赖优先级队列。比如，赫夫曼编码、图的最短路径、最小生成树算法等等。

#### 堆的应用：求 Top K

可以维护一个大小为 K 的小顶堆，顺序遍历数组，从数组中取出取数据与堆顶元素比较。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理，继续遍历数组。这样等数组中的数据都遍历完之后，堆中的数据就是前 K 大数据了。

##### 合并有序小文件

假设有 100 个小文件，每个文件的大小是 100MB，每个文件中存储的都是有序的字符串。将这些 100 个小文件合并成一个有序的大文件。这里就会用到优先级队列。

整体思路有点像归并排序中的合并函数。从这 100 个文件中，各取第一个字符串，放入数组中，然后比较大小，把最小的那个字符串放入合并后的大文件中，并从数组中删除。

这里就可以用到优先级队列，也可以说是堆。将从小文件中取出来的字符串放入到小顶堆中，那堆顶的元素，也就是优先级队列队首的元素，就是最小的字符串。将这个字符串放入到大文件中，并将其从堆中删除。然后再从小文件中取出下一个字符串，放入到堆中。循环这个过程，就可以将 100 个小文件中的数据依次放入到大文件中。

删除堆顶数据和往堆中插入数据的时间复杂度都是 O(logn)，n 表示堆中的数据个数，这里就是 100。

##### 利用堆求中位数

如何求动态数据集合中的中位数。

中位数，就是处在中间位置的那个数。如果数据的个数是奇数，把数据从小到大排列，那第 `n/2+1` 个数据就是中位数；如果数据的个数是偶数的话，那处于中间位置的数据有两个，第 `n/2` 个和第 `n/2+1` 个数据，这个时候，可以随意取一个作为中位数，比如取两个数中靠前的那个，就是第 `n/2` 个数据。

对于一组静态数据，中位数是固定的，可以先排序，第 `n/2` 个数据就是中位数。每次询问中位数的时候，我们直接返回这个固定的值就好了。所以，尽管排序的代价比较大，但是边际成本会很小。但是，如果我们面对的是动态数据集合，中位数在不停地变动，如果再用先排序的方法，每次询问中位数的时候，都要先进行排序，那效率就不高了。

借助堆这种数据结构，就可以非常高效地实现求中位数操作。

需要维护两个堆，一个大顶堆，一个小顶堆。大顶堆中存储前半部分数据，小顶堆中存储后半部分数据，且小顶堆中的数据都大于大顶堆中的数据。

也就是说，如果有 n 个数据，n 是偶数，我们从小到大排序，那前 `n/2` 个数据存储在大顶堆中，后 `n/2` 个数据存储在小顶堆中。这样，大顶堆中的堆顶元素就是要找的中位数。如果 n 是奇数，情况是类似的，大顶堆就存储 `n/2+1` 个数据，小顶堆中就存储 `n/2` 个数据。

数据是动态变化的，当新添加一个数据的时候，如何调整两个堆，让大顶堆中的堆顶元素继续是中位数呢？

如果新加入的数据小于等于大顶堆的堆顶元素，就将这个新数据插入到大顶堆；如果新加入的数据大于等于小顶堆的堆顶元素，就将这个新数据插入到小顶堆。

这个时候，我们可以从一个堆中不停地将堆顶元素移动到另一个堆，通过这样的调整，来让两个堆中的数据满足上面的约定。

利用两个堆，一个大顶堆、一个小顶堆，实现在动态数据集合中求中位数的操作。插入数据因为需要涉及堆化，所以时间复杂度变成了 O(logn)，但是求中位数只需要返回大顶堆的堆顶元素就可以了，所以时间复杂度就是 O(1)。

### [图](https://time.geekbang.org/column/article/68334)

图中的元素叫作顶点（vertex），图中的一个顶点可以与任意其他顶点建立连接关系，叫作边（edge）。
跟顶点相连接的边的条数，叫作顶点的度（degree）。

存储方法

- 邻接矩阵（Adjacency Matrix）：最直观的一种存储方法，邻接矩阵的底层依赖一个二维数组。
- 邻接表（Adjacency List）。

逆邻接表

深度优先搜索算法和广度优先搜索（Breadth-First-Search）算法都是基于“图”这种数据结构的。

#### 无向图

#### 有向图

在有向图中，度分为入度（In-degree）和出度（Out-degree）。

#### 带权图（weighted graph）

在带权图中，每条边都有一个权重（weight）

### [Trie 树](https://time.geekbang.org/column/article/72414)

Trie 树，也叫“字典树”，一种专门处理字符串匹配的数据结构，用来解决在一组字符串集合中快速查找某个字符串的问题。

Trie 树的本质，就是利用字符串之间的公共前缀，将重复的前缀合并在一起。

Trie 树最有优势的是查找前缀匹配的字符串
