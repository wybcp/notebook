# 开发设计规范

## Key设计

key的一个格式约定：`object-type:id:field`。用":"分隔域，用"."作为单词间的连接，如"`comment:12345:reply.to`"。不推荐含义不清的key和特别长的key。

适当的情况下缩减键的长度可以减少内存浪费。

一般的设计方法如下：

1. 把表名转换为key前缀 如tag:
2. 第2段放置用于区分区key的字段，对应mysql中的主键的列名,如userid
3. 第3段放置主键值,如2、3、4....
4. 第4段写要存储的列名

例如用户表`user`, 转换为key-value存储：

| userid | username | password | email        |
| :----- | :------- | :------- | :----------- |
| 9      | Bobo     | 123456   | bobo@163.com |

```shell
set user:userid:9:username bobo
set user:userid:9:password 123456
set user:userid:9:email   bobo@163.com
```

例如，查看某个用户的所有信息为：

```shell
keys user:userid:9*
```

如果另一个列也常常被用来查找，比如`username`，则也要相应的生成一条按照该列为主的key-value，例如：

```shell
user:username:bobo:uid 9
```

此时相当于RDBMS中在username上加索引，我们可以根据
`username:bobo:uid`，查出userid=9，再查`user:9:password/email` ...

## 超时设置

从业务需求逻辑和内存的角度，尽可能的设置key存活时间。

## 数据异常处理

程序应该处理如果redis数据丢失时的清理redis内存和重新加载的过程。

## 内存考虑

1. 只要有可能的话，就尽量使用散列键而不是字符串键来储存键值对数据，因为散列键管理方便、能够避免键名冲突、并且还能够节约内存。

2. 如果将redis作为cache进行频繁读写和超时删除等，此时应该避免设置较大的k-v，因为这样会导致redis的内存碎片增加，导致rss占用较大，最后被操作系统OOM killer干掉。

  如果采用序列化考虑通用性，请采用json相关的库进行处理，如果对内存大小和速度都很关注的，推荐使用messagepack进行序列化和反序列化

  如果需要计数器，请将计数器的key通过天或者小时分割，比如下边的设计
  ![一般设计](https://raw.githubusercontent.com/gnuhpc/All-About-Redis/master/CodeDesignRule/mem1.png)

  更好的一个设计是采用hash：

  ![hash设计](https://raw.githubusercontent.com/gnuhpc/All-About-Redis/master/CodeDesignRule/mem3.png)

3. 各种数据结构及其占用内存的benchmark测试

| set个数 | 每个set的元素总数 | 内存占用 | Key大小 | Value大小 |
| ------- | ----------------- | -------- | ------- | --------- |
| 100     | 100               | 1.88M    | 7       | 36        |
| 100     | 1000              | 10.75M   | 7       | 36        |
| 100     | 10000             | 111.12M  | 7       | 36        |
| 1000    | 100               | 11.59M   | 8       | 36        |
| 1000    | 1000              | 100.35M  | 8       | 36        |
| 1000    | 10000             | 1.08G    | 8       | 36        |
| 10000   | 100               | 108.71M  | 9       | 36        |
| 10000   | 1000              | 996.23M  | 9       | 36        |

| zset个数 | 每个zset的元素总数 | 内存占用 | Key大小 | Value大小 |
| -------- | ------------------ | -------- | ------- | --------- |
| 100      | 100                | 1.62M    | 8       | 49        |
| 100      | 1000               | 15.91M   | 8       | 49        |
| 100      | 10000              | 162.06M  | 8       | 49        |
| 1000     | 100                | 8.71M    | 9       | 49        |
| 1000     | 1000               | 151.87M  | 9       | 49        |
| 1000     | 10000              | 1.58G    | 9       | 49        |
| 10000    | 100                | 79.83M   | 10      | 49        |
| 10000    | 1000               | 1.48G    | 10      | 49        |

| hash个数 | 每个hash的元素总数 | 内存占用 | Key大小 | Value大小 |
| -------- | ------------------ | -------- | ------- | --------- |
| 100      | 100                | 1.63M    | 8       | 49        |
| 100      | 1000               | 6.29M    | 8       | 49        |
| 100      | 10000              | 156.91M  | 8       | 49        |
| 1000     | 100                | 8.71M    | 9       | 49        |
| 1000     | 1000               | 55.59M   | 9       | 49        |
| 1000     | 10000              | 1.52G    | 9       | 49        |
| 10000    | 100                | 79.83M   | 10      | 49        |
| 10000    | 1000               | 548.58M  | 10      | 49        |

| list个数 | 每个list的元素总数 | 内存占用 | Key大小 | Value大小 |
| -------- | ------------------ | -------- | ------- | --------- |
| 100      | 100                | 1.23M    | 8       | 36        |
| 100      | 1000               | 10.00M   | 8       | 36        |
| 100      | 10000              | 92.40M   | 8       | 36        |
| 1000     | 100                | 4.83M    | 9       | 36        |
| 1000     | 1000               | 92.52M   | 9       | 36        |
| 1000     | 10000              | 916.47M  | 9       | 36        |
| 10000    | 100                | 40.76M   | 10      | 36        |
| 10000    | 1000               | 917.69M  | 10      | 36        |

| string个数 | 内存占用 | Key大小 | Value大小 |
| ---------- | -------- | ------- | --------- |
| 100        | 846.79K  | 13      | 36        |
| 1000       | 966.29K  | 13      | 36        |
| 10000      | 2.16M    | 13      | 36        |
| 100000     | 130.88M  | 13      | 36        |

## 延迟考虑

### 尽可能使用批量操作

- mget、hmget而不是get和hget，对于set也是如此，1次网络时间+n次命令时间。
- lpush向一个list一次性导入多个元素，而不用lset一个个添加
- LRANGE 一次取出一个范围的元素，也不用LINDEX一个个取出

### 尽可能的把redis和APP SERVER部署在一个网段甚至一台机器。

### 处理大数据

对于数据量较大的集合，不要轻易进行删除操作，这样会阻塞服务器，一般采用重命名+批量删除的策略：

### 尽可能使用不要超过1M大小的kv。

### 减少对大数据集的高时间复杂度的操作

根据复杂度计算，如下命令可以优化:

![优化](https://raw.githubusercontent.com/gnuhpc/All-About-Redis/master/CodeDesignRule/lat1.png)

### 尽可能使用pipeline操作

一次性的发送命令比一个个发要减少网络延迟和单个处理开销。一个性能测试结果为（注意并不是pipeline越大效率越高，注意最后一个测试结果）。

### 如果要sort的集合非常大的话排序就会消耗很长时间。

由于redis单线程的，所以长时间的排序操作会阻塞其他client的请求。解决办法是通过主从复制机制将数据复制到多个slave上。然后我们只在slave上做排序操作。把可能的对排序结果缓存。

另外就是一个方案是就是采用sorted set对需要按某个顺序访问的集合建立索引。